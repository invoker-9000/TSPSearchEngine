Multiple Processors Scheduling in Operating System - javatpoint ? SCROLL TO TOP Home OS C Java PHP HTML CSS Bootstrap JavaScript jQuery jQuery UI Quiz Projects Interview Q Comment Forum Training OS Tutorial OS Tutorial Types of OS Process Management Introduction Attributes of a Process Process States Process Schedulers Process Queues Times Related to Process CPU Scheduling Scheduling Algorithms FCFS Scheduling Convoy Effect in FCFS FCFS with overhead SJF Scheduling Burst Time Prediction SRTF scheduling SRTF GATE 2011 Example Round Robin Scheduling RR scheduling Example HRRN Scheduling HRNN Example Priority Scheduling Non Preemptive Priority Preemptive Priority SRTF:IO bound processes Synchronization Introduction Critical Section Problem Lock Variable Mechanism TSL Mechanism Priority Inversion in TSL Turn Variable Interested Variable Paterson Solution Without Busy Waiting Sleep and Wake Semaphore Introduction Counting Semaphore Problem on counting semaphore Binary Semaphore Deadlocks Introduction strategies Handling Deadlock Prevention Deadlock Avoidance Resource Allocation Graph Detection using RAG Detection and Recovery Memory Management Introduction Fixed Partitioning Dynamic Partitioning Compaction Bit Map for Dynamic Partitioning Linked List for Dynamic Partitioning Partitioning Algorithms GATE on Best Fit & First Fit Need for Paging Paging with Example Binary Addresses Physical & Logical Address Page Table Mapping from page table Page Table Entry Page Table Size Finding Optimal Page Size Virtual Memory Look aside Buffer GATE question on TLB Demand Paging Inverted Page Table Page Replacement Gate on LRU and FIFO Numerical on LRU, FIFO Beladys Anamoly Segmentation Paging VS Segmentation Segmented Paging File Management Attributes of the File Operations on the File File Access Methods Directory Structure Single level Directory Two level Directory Tree structured Directory Acyclic Graph Directories File System File System Structure Master Boot Record On Disk Data Structures In memory Data structures Directory Implementation Allocation Methods Contiguous Allocation Linked List Allocation File Allocation Table Indexed Allocation Linked Index Allocation Inode Free space Management Disk Scheduling FCFS Scheduling SSTF Scheduling SCAN and C-SCAN Look and C-Look Numerical on SSTF Numerical on Disk Misc Functions of OS Mobile OS Swapping in OS Threads in OS Fedora Operating System Uses of Operating System Producer-Consumer problem Dining Philosophers Problem Readers Writers Problem History Of OS Banker's Algorithm in OS What is the context switching in the operating system Internal vs. External Fragmentation Multiprocessing Operating system Multiprogramming vs Multitasking Network Operating System Latest Operating System System Calls in Operating System Multitasking Operating System Distributed Operating System Fragmentation in Operating System Multithreading Models in Operating system Operating system services Batch Operating System Embedded Operating System Time-Sharing vs Real-Time Operating System Multi-User Operating System Memory Management Monolithic Structure of Operating System MS-DOS Operating System Spooling in Operating System Network Operating System vs Distributed Operating System Operating system vs Application software System Software vs Operating System Real-Time operating system Booting in Operating System Layered Structure of Operating System Multiprogramming vs. Time Sharing Operating System Distributed File System Multiprogramming Operating System Server Operating System 32 bit vs 64 bit Operating System Single User Operating System Process vs Program Operating System Security Components of Operating System GUI Operating System Android Operating System Buffering in Operating System Device Driver in Operating System Best Operating System for Hacking Clustered Operating System Android vs Windows OS Scheduler vs Dispatcher Deadlock vs Starvation Semaphore vs Monitor Boot Block and Bad Block in Operating System Hard and Soft Real-Time Operating System Concurrency in Operating System Microkernel in Operating System Protection in Operating System Benefits of Multithreading Host vs Guest Operating System Livelock in Operating System Dual Mode Operations in Operating System What is Access Token in Operating System Deadlock Detection in Distributed Systems CUI vs GUI Monolithic vs layered Operating System Mutex vs Semaphore What is Interleaved Memory Trap vs Interrupt in Operating System Open-Source Operating System Multiple Processors Scheduling in Operating System Starvation and Aging in Operating Systems Best Android Operating System for PC Device Management in Operating System Disk Controller in Operating System Views of Operating System Tasks in Real-Time Systems What is RPC in Operating System C-SCAN vs SSTF Disk Scheduling Algorithm Look vs C-Look Disk Scheduling Algorithm SCAN vs C-SCAN Disk Scheduling Algorithm SCAN vs FCFS Disk Scheduling Algorithm Lamport's Bakery Algorithm Basic Disk vs Dynamic Disk What is Zombie Process FCFS vs SSTF Disk Scheduling Algorithm LRU vs LFU Page Replacement Algorithm SSTF vs C-LOOK Disk Scheduling Algorithm C-LOOK vs C-SCAN Disk Scheduling Algorithm Rotational Latency vs Disk Access Time in Disk Scheduling SSTF vs LOOK Disk Scheduling Algorithm Virtual vs Physical Address Address binding in Operating System Preemptive vs Non-Preemptive Scheduling Properties of Operating System What is Processor Affinity MCQ Operating System MCQ OS MCQ Part-2 next ? ? prev Multiple Processors Scheduling in Operating System Multiple processor scheduling or multiprocessor scheduling focuses on designing the system's scheduling function, which consists of more than one processor. Multiple CPUs share the load (load sharing) in multiprocessor scheduling so that various processes run simultaneously. In general, multiprocessor scheduling is complex as compared to single processor scheduling. In the multiprocessor scheduling, there are many processors, and they are identical, and we can run any process at any time. The multiple CPUs in the system are in close communication, which shares a common bus, memory, and other peripheral devices. So we can say that the system is tightly coupled. These systems are used when we want to process a bulk amount of data, and these systems are mainly used in satellite, weather forecasting, etc. There are cases when the processors are identical, i.e., homogenous, in terms of their functionality in multiple-processor scheduling. We can use any processor available to run any process in the queue. Multiprocessor systems may be heterogeneous (different kinds of CPUs) or homogenous (the same CPU). There may be special scheduling constraints, such as devices connected via a private bus to only one CPU. There is no policy or rule which can be declared as the best scheduling solution to a system with a single processor. Similarly, there is no best scheduling solution for a system with multiple processors as well. Approaches to Multiple Processor Scheduling There are two approaches to multiple processor scheduling in the operating system: Symmetric Multiprocessing and Asymmetric Multiprocessing. Symmetric Multiprocessing: It is used where each processor is self-scheduling. All processes may be in a common ready queue, or each processor may have its private queue for ready processes. The scheduling proceeds further by having the scheduler for each processor examine the ready queue and select a process to execute. Asymmetric Multiprocessing: It is used when all the scheduling decisions and I/O processing are handled by a single processor called the Master Server. The other processors execute only the user code. This is simple and reduces the need for data sharing, and this entire scenario is called Asymmetric Multiprocessing. Processor Affinity Processor Affinity means a process has an affinity for the processor on which it is currently running. When a process runs on a specific processor, there are certain effects on the cache memory. The data most recently accessed by the process populate the cache for the processor. As a result, successive memory access by the process is often satisfied in the cache memory. Now, suppose the process migrates to another processor. In that case, the contents of the cache memory must be invalidated for the first processor, and the cache for the second processor must be repopulated. Because of the high cost of invalidating and repopulating caches, most SMP(symmetric multiprocessing) systems try to avoid migrating processes from one processor to another and keep a process running on the same processor. This is known as processor affinity. There are two types of processor affinity, such as: Soft Affinity: When an operating system has a policy of keeping a process running on the same processor but not guaranteeing it will do so, this situation is called soft affinity. Hard Affinity: Hard Affinity allows a process to specify a subset of processors on which it may run. Some Linux systems implement soft affinity and provide system calls like sched_setaffinity() that also support hard affinity. Load Balancing Load Balancing is the phenomenon that keeps the workload evenly distributed across all processors in an SMP system. Load balancing is necessary only on systems where each processor has its own private queue of a process that is eligible to execute. Load balancing is unnecessary because it immediately extracts a runnable process from the common run queue once a processor becomes idle. On SMP (symmetric multiprocessing), it is important to keep the workload balanced among all processors to utilize the benefits of having more than one processor fully. One or more processors will sit idle while other processors have high workloads along with lists of processors awaiting the CPU. There are two general approaches to load balancing: Push Migration: In push migration, a task routinely checks the load on each processor. If it finds an imbalance, it evenly distributes the load on each processor by moving the processes from overloaded to idle or less busy processors. Pull Migration:Pull Migration occurs when an idle processor pulls a waiting task from a busy processor for its execution. Multi-core Processors In multi-core processors, multiple processor cores are placed on the same physical chip. Each core has a register set to maintain its architectural state and thus appears to the operating system as a separate physical processor. SMP systems that use multi-core processors are faster and consume less power than systems in which each processor has its own physical chip. However, multi-core processors may complicate the scheduling problems. When the processor accesses memory, it spends a significant amount of time waiting for the data to become available. This situation is called a Memory stall. It occurs for various reasons, such as cache miss, which is accessing the data that is not in the cache memory. In such cases, the processor can spend upto 50% of its time waiting for data to become available from memory. To solve this problem, recent hardware designs have implemented multithreaded processor cores in which two or more hardware threads are assigned to each core. Therefore if one thread stalls while waiting for the memory, the core can switch to another thread. There are two ways to multithread a processor: Coarse-Grained Multithreading: A thread executes on a processor until a long latency event such as a memory stall occurs in coarse-grained multithreading. Because of the delay caused by the long latency event, the processor must switch to another thread to begin execution. The cost of switching between threads is high as the instruction pipeline must be terminated before the other thread can begin execution on the processor core. Once this new thread begins execution, it begins filling the pipeline with its instructions. Fine-Grained Multithreading: This multithreading switches between threads at a much finer level, mainly at the boundary of an instruction cycle. The architectural design of fine-grained systems includes logic for thread switching, and as a result, the cost of switching between threads is small. Symmetric Multiprocessor Symmetric Multiprocessors (SMP) is the third model. There is one copy of the OS in memory in this model, but any central processing unit can run it. Now, when a system call is made, the central processing unit on which the system call was made traps the kernel and processed that system call. This model balances processes and memory dynamically. This approach uses Symmetric Multiprocessing, where each processor is self-scheduling. The scheduling proceeds further by having the scheduler for each processor examine the ready queue and select a process to execute. In this system, this is possible that all the process may be in a common ready queue or each processor may have its private queue for the ready process. There are mainly three sources of contention that can be found in a multiprocessor operating system. Locking system: As we know that the resources are shared in the multiprocessor system, there is a need to protect these resources for safe access among the multiple processors. The main purpose of the locking scheme is to serialize access of the resources by the multiple processors. Shared data: When the multiple processors access the same data at the same time, then there may be a chance of inconsistency of data, so to protect this, we have to use some protocols or locking schemes. Cache coherence: It is the shared resource data that is stored in multiple local caches. Suppose two clients have a cached copy of memory and one client change the memory block. The other client could be left with an invalid cache without notification of the change, so this conflict can be resolved by maintaining a coherent view of the data. Master-Slave Multiprocessor In this multiprocessor model, there is a single data structure that keeps track of the ready processes. In this model, one central processing unit works as a master and another as a slave. All the processors are handled by a single processor, which is called the master server. The master server runs the operating system process, and the slave server runs the user processes. The memory and input-output devices are shared among all the processors, and all the processors are connected to a common bus. This system is simple and reduces data sharing, so this system is called Asymmetric multiprocessing. Virtualization and Threading In this type of multiple processor scheduling, even a single CPU system acts as a multiple processor system. In a system with virtualization, the virtualization presents one or more virtual CPUs to each of the virtual machines running on the system. It then schedules the use of physical CPUs among the virtual machines. Most virtualized environments have one host operating system and many guest operating systems, and the host operating system creates and manages the virtual machines. Each virtual machine has a guest operating system installed, and applications run within that guest. Each guest operating system may be assigned for specific use cases, applications, or users, including time-sharing or real-time operation. Any guest operating-system scheduling algorithm that assumes a certain amount of progress in a given amount of time will be negatively impacted by the virtualization. A time-sharing operating system tries to allot 100 milliseconds to each time slice to give users a reasonable response time. A given 100 millisecond time slice may take much more than 100 milliseconds of virtual CPU time. Depending on how busy the system is, the time slice may take a second or more, which results in a very poor response time for users logged into that virtual machine. The net effect of such scheduling layering is that individual virtualized operating systems receive only a portion of the available CPU cycles, even though they believe they are receiving all cycles and scheduling all of those cycles. The time-of-day clocks in virtual machines are often incorrect because timers take no longer to trigger than they would on dedicated CPUs. Virtualizations can thus undo the good scheduling algorithm efforts of the operating systems within virtual machines. Next Topic Starvation and Aging in Operating Systems ? prev next ? For Videos Join Our Youtube Channel: Join Now Feedback Send your Feedback to [email protected] Help Others, Please Share Learn Latest Tutorials Splunk SPSS Swagger Transact-SQL Tumblr ReactJS Regex Reinforcement Learning R Programming RxJS React Native Python Design Patterns Python Pillow Python Turtle Keras Preparation Aptitude Reasoning Verbal Ability Interview Questions Company Questions Trending Technologies Artificial Intelligence AWS Selenium Cloud Computing Hadoop ReactJS Data Science Angular 7 Blockchain Git Machine Learning DevOps B.Tech / MCA DBMS Data Structures DAA Operating System Computer Network Compiler Design Computer Organization Discrete Mathematics Ethical Hacking Computer Graphics Software Engineering Web Technology Cyber Security Automata C Programming C++ Java .Net Python Programs Control System Data Mining Data Warehouse Javatpoint Services JavaTpoint offers too many high quality services. Mail us on [email protected], to get more information about given services. Website Designing Website Development Java Development PHP Development WordPress Graphic Designing Logo Digital Marketing On Page and Off Page SEO PPC Content Development Corporate Training Classroom and Online Training Data Entry Training For College Campus JavaTpoint offers college campus training on Core Java, Advance Java, .Net, Android, Hadoop, PHP, Web Technology and Python. Please mail your requirement at [email protected] Duration: 1 week to 2 week Like/Subscribe us for latest updates or newsletter Learn Tutorials Learn Java Learn Data Structures Learn C Programming Learn C++ Tutorial Learn C# Tutorial Learn PHP Tutorial Learn HTML Tutorial Learn JavaScript Tutorial Learn jQuery Tutorial Learn Spring Tutorial Our Websites Javatpoint.com Hindi100.com Lyricsia.com Quoteperson.com Jobandplacement.com Our Services Website Development Android Development Website Designing Digital Marketing Summer Training Industrial Training College Campus Training Contact Address: G-13, 2nd Floor, Sec-3 Noida, UP, 201301, India Contact No: 0120-4256464, 9990449935 Contact Us Subscribe Us Privacy Policy Sitemap About Me ? Copyright 2011-2021 www.javatpoint.com. All rights reserved. Developed by JavaTpoint.
